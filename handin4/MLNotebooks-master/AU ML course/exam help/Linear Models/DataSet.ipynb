{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from subprocess import call\n",
    "import pickle\n",
    "\n",
    "class TargetFunction():\n",
    "    def __init__(self, function, string_representation): \n",
    "        self.function = function\n",
    "        self.string_representation = string_representation\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.string_representation\n",
    "    \n",
    "\n",
    "class DataSet:\n",
    "    \n",
    "    # Potential features:\n",
    "    # - Add parameter that allows to decide if bias should be encoded in data.\n",
    "    # - Add parameter that allows to decide if labels should be {0, 1} or {-1, +1}\n",
    "    def __init__(self, name, n=100, d=2, var=0.8, means=np.array([[8,2], [2,8]]), xlim=[0,10], ylim=[0,10]):\n",
    "        self.xlim = xlim\n",
    "        self.ylim = ylim\n",
    "        \n",
    "        self.name = name\n",
    "        if name == \"perceptron\": \n",
    "            self.X, self.y = self.make_classification(n, 2, means = np.array([[2,4], [8,5]]))\n",
    "        elif name == \"cats_vs_dogs\":\n",
    "            self.X, self.y = self.cifar_cats_dogs() \n",
    "        elif name == \"pocket\":\n",
    "            self.X, self.y = self.make_classification(n, 2, means = np.array([[3,5], [8,5]]), variance=1.7)\n",
    "        elif name == \"linear_regression\":\n",
    "            self.linreg = True\n",
    "            self.X, self.y, self.target_function = self.make_regression(n, d)\n",
    "        elif name == \"linear_classification\":\n",
    "            pass\n",
    "        elif name == \"breast_cancer\":\n",
    "            self.X, self.y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "            n, d = self.X.shape\n",
    "            self.X = np.concatenate((np.ones(n).reshape(n, 1), self.X), axis=1)\n",
    "            self.y = 2*self.y-1\n",
    "            self.normalize_mean()\n",
    "            self.X += 1 # add small noise so X^TX is invertible \n",
    "            #update plot limits after normalization\n",
    "\n",
    "        elif name == \"breast_cancer_2d\": \n",
    "            X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "            self.X, self.y = self.pca_2d(X, y)\n",
    "            self.normalize_mean()\n",
    "            self.X += 1  # add small noise so X^TX is invertible \n",
    "            #update plot limits after normalization\n",
    "            self.xlim = [np.min(self.X[:,1]), np.max(self.X[:,1])]\n",
    "            self.ylim = [np.min(self.X[:,2]), np.max(self.X[:,2])]\n",
    "            \n",
    "        elif name == \"logistic_regression\":\n",
    "            self.X, self.y = self.make_classification(n, 2, means = means, variance=var)\n",
    "        elif name == \"not_linearly_seperable\":\n",
    "            self.X, self.y = self.non_linear_circle(n, 0.35)\n",
    "        \n",
    "    def normalize(self):\n",
    "        self.X = (self.X - np.mean(self.X, axis=0)) / np.std(self.X, axis=0)\n",
    "    def normalize_mean(self):\n",
    "        self.X = self.X - np.mean(self.X, axis=0)\n",
    "    def normalize_std(self):\n",
    "        self.X = self.X / np.std(self.X, axis=0)\n",
    "        \n",
    "        \n",
    "    def pca_2d(self, X, y): \n",
    "        n, _ = X.shape\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(X)\n",
    "\n",
    "        X = X @ pca.components_[:2].T\n",
    "        X = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
    "        \n",
    "        self.xlim = [np.min(X[:,1]), np.max(X[:,1])]\n",
    "        self.ylim = [np.min(X[:,2]), np.max(X[:,2])]\n",
    "        \n",
    "        return X, y*2-1 # change from {0, 1} to {-1, +1}\n",
    "            \n",
    "\n",
    "    def non_linear_circle(self, n, variance=0.2):\n",
    "        ''' Generate a binary classification problem that is not linearly seperable (circle). '''\n",
    "        r_class0 = 0.3\n",
    "        r_class1 = 2\n",
    "\n",
    "        # for each point, normally distribute around radius and uniformly pick an angle. \n",
    "        angles = np.random.rand(n)*2*np.pi\n",
    "        noisy_r_0 = np.random.normal(loc=r_class0, scale=variance, size=n//2)\n",
    "        noisy_r_1 = np.random.normal(loc=r_class1, scale=variance, size=n//2)\n",
    "\n",
    "\n",
    "        # compute (x,y) points from polar coordinates (r, angle). \n",
    "        X_0 = noisy_r_0 * np.cos(angles[:n//2])\n",
    "        y_0 = noisy_r_0 * np.sin(angles[:n//2])\n",
    "        X_1 = noisy_r_1 * np.cos(angles[n//2:])\n",
    "        y_1 = noisy_r_1 * np.sin(angles[n//2:])\n",
    "\n",
    "        X_0 = np.concatenate((np.ones(n//2).reshape(n//2, 1), X_0.reshape(n//2, 1), y_0.reshape(n//2, 1)), axis=1)\n",
    "        X_1 = np.concatenate((np.ones(n//2).reshape(n//2, 1), X_1.reshape(n//2, 1), y_1.reshape(n//2, 1)), axis=1)\n",
    "        X = np.concatenate((X_0, X_1), axis=0)\n",
    "        y = np.concatenate((np.zeros(n//2), np.ones(n//2)))\n",
    "\n",
    "        perm = np.random.permutation(n)\n",
    "\n",
    "        X = X[perm]\n",
    "        y = y[perm]\n",
    "        return X, y\n",
    "        \n",
    "    def make_regression(self, n, d):\n",
    "        \"\"\" For now assumes d=2, make data normally distributed around line. \"\"\"\n",
    "        \n",
    "        if d == 2:\n",
    "            # Generate normally distributed noise that displaces points from line. \n",
    "            noise_variance = 0.5\n",
    "            normal_distributed_noise = np.random.normal(loc=0, scale=noise_variance, size=n)\n",
    "\n",
    "            # Generate random line f(x)=ax+b such that points normally distributed around line will \n",
    "            # have high probability of being inside plot. \n",
    "            b = np.random.rand(1)*5+2 # Let 'b' be in [4, 6] uniform random\n",
    "            sign = np.random.choice([-1, +1])\n",
    "            a = sign* np.random.rand(1)/10*4 # let 'a' be in [-4/10+noise_var, 4/10-noise_var] so all data are in uniform 10,10 box\n",
    "\n",
    "            target_function = TargetFunction(lambda x: a*x+b, str(round(a[0], 2)) + \"*x+\" + str(round(b[0], 2)))\n",
    "            target_function.w = [b, a]\n",
    "\n",
    "            xs = np.ones((n, 2)) \n",
    "            xs[:, 1] = np.random.rand(n)*10 \n",
    "\n",
    "            ys = target_function.function(xs[:, 1]) + normal_distributed_noise\n",
    "\n",
    "            return xs, ys, target_function\n",
    "        else:\n",
    "            # Generate weight vector\n",
    "            w = np.random.rand(d)\n",
    "            \n",
    "            noise_variance = 0.05\n",
    "            normal_distributed_noise = np.random.normal(loc=0, scale=noise_variance, size=n)\n",
    "            \n",
    "            X = np.random.rand(n, d)\n",
    "            y = X @ w + normal_distributed_noise\n",
    "            \n",
    "            return X, y, None\n",
    "        \n",
    "        \n",
    "\n",
    "    def make_classification(self, n, d, means=None, num_classes=2, linear_seperable=False, variance=0.8):\n",
    "        \"\"\" Creates data for a 'num_classes' classification problem. All points are generated in a \n",
    "        cube [0, 2]^d. Each class is generated as a normal distribution N(Âµ, 1) around a \n",
    "        randomly generated mean. \n",
    "\n",
    "        \"\"\"\n",
    "        # Generate num_classes means\n",
    "        if means is None: \n",
    "            means = np.random.rand(num_classes, d)*10\n",
    "        \n",
    "        # Initialize data matrix and labels array\n",
    "        # Encode 1's in first dimension\n",
    "        X = np.ones((n, d+1))\n",
    "        y = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "        for i in range(n):\n",
    "            y[i] = np.random.choice(num_classes)\n",
    "            X[i, 1:d+1] = np.random.normal(loc=means[y[i]], scale=variance)\n",
    "\n",
    "        # Have labels be {-1, +1}\n",
    "        y = y*2-1\n",
    "            \n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\" Assumes the data is 2d and plots it. Throws exception if data isn't 2d (with bias encoded). \n",
    "        \n",
    "        \"\"\"\n",
    "        n, d = self.X.shape\n",
    "        assert d == 3, \"Data needs to be 2d (with bias encoded) to be plotted.\"\n",
    "        \n",
    "        if set(self.y) != {-1, +1}: self.y = self.y*2-1\n",
    "\n",
    "        X_class_0 = self.X[self.y == -1]\n",
    "        X_class_1 = self.X[self.y == 1]\n",
    "        fig, ax_data = plt.subplots(1, 1, figsize=(4, 4))\n",
    "        \n",
    "        ax_data.set_title(\"Dataset: \" + self.name)\n",
    "        ax_data.set_xlabel(\"X dimension of data\")\n",
    "        ax_data.set_ylabel(\"Y dimension of data\")\n",
    "        ax_data.set_xlim(self.xlim[0], self.xlim[1])\n",
    "        ax_data.set_ylim(self.ylim[0], self.ylim[1])\n",
    "        ax_data.plot(X_class_0[:,1], X_class_0[:,2], 'go')\n",
    "        ax_data.plot(X_class_1[:,1], X_class_1[:,2], 'bx')\n",
    "        fig.canvas.draw()\n",
    "        \n",
    "    def plot_regression(self):\n",
    "        n, d = self.X.shape\n",
    "        #assert d == 2, \"Data needs to be 2d (with bias encoded) to be plotted.\"\n",
    "        \n",
    "        plt.title(\"Dataset: \" + self.name + \", Target Function: \" + str(self.target_function))\n",
    "        plt.xlabel(\"X dimension of data\")\n",
    "        plt.ylabel(\"Y dimension of data\")\n",
    "        plt.xlim(0, 10)\n",
    "        plt.ylim(0, 10)\n",
    "        plt.plot(self.X[:,1], self.y, 'go')\n",
    "        plt.plot([0, 10], [self.target_function.function(0), self.target_function.function(10)], '--c')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # CIFAR and CATSvsDOGS\n",
    "\n",
    "    def download_cifar10(self):\n",
    "        ''' Downloads CIFAR10 if there is no local copy. '''\n",
    "\n",
    "        # If there is no local copy of CIFAR10 then download it. \n",
    "        if not os.path.exists(\"cifar-10-python.tar.gz\"):\n",
    "            print(\"You don't have the 'cifar-10' dataset! \")\n",
    "            print(\"Don't worry, I'll start downloading it right away. \")\n",
    "            print(\"It's 163 Mb so it might take a few minutes. \")\n",
    "            print(\"Downloading... \", end='')\n",
    "            call(\n",
    "                \"wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\",\n",
    "                shell=True\n",
    "            )\n",
    "            print(\"DONE!\")\n",
    "\n",
    "        # Extract the .tar.gz file. \n",
    "        cifar_python_directory = os.path.abspath(\"cifar-10-batches-py\")\n",
    "        if not os.path.exists(cifar_python_directory):\n",
    "            print(\"Extracting the archive... \", end='')\n",
    "            call(\n",
    "                \"tar -zxvf cifar-10-python.tar.gz\",\n",
    "                shell=True\n",
    "            )\n",
    "            print(\"DONE!\")\n",
    "\n",
    "    def load_cifar(self):\n",
    "        ''' Loads a single batch of CIFAR10. '''\n",
    "\n",
    "        # Download CIFAR if there is no local copy. \n",
    "        self.download_cifar10()\n",
    "\n",
    "        # Open a single batch of the CIFAR10 dataset. \n",
    "        with open(\"cifar-10-batches-py/data_batch_1\", 'rb') as fo:\n",
    "            data_dict = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "        # Retrieve data and labels (dtype is uint8)\n",
    "        X = data_dict[b'data']\n",
    "        y = np.array(data_dict[b'labels'])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def cifar_cats_dogs(self):\n",
    "        # Load the cifar dataset\n",
    "        X, y = self.load_cifar()\n",
    "\n",
    "        # Get only the dogs/cats. Dogs are represented as '5'\n",
    "        # and cats as 3\n",
    "        X = X[np.logical_or(y==5, y==3)]\n",
    "        y = y[np.logical_or(y==5, y==3)]\n",
    "        y = (y == 3) # 3 -> True,  5 -> False\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def show_cats_vs_dogs(self):\n",
    "        n, d = self.X.shape\n",
    "\n",
    "        X = self.X.reshape(n, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "\n",
    "        fig, axes = plt.subplots(5, 5, figsize=(8,8))\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axes[i,j].imshow(X[i+j*5])\n",
    "\n",
    "        fig.canvas.draw()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
