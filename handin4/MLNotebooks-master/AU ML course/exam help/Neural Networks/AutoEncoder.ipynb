{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "[(<tf.Tensor 'gradients_11/MatMul_15_grad/tuple/control_dependency_1:0' shape=(784, 10) dtype=float32>, <tf.Variable 'Variable_20:0' shape=(784, 10) dtype=float32_ref>), (<tf.Tensor 'gradients_11/add_15_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>, <tf.Variable 'Variable_21:0' shape=(10,) dtype=float32_ref>), (<tf.Tensor 'gradients_11/MatMul_16_grad/tuple/control_dependency_1:0' shape=(10, 784) dtype=float32>, <tf.Variable 'Variable_22:0' shape=(10, 784) dtype=float32_ref>), (<tf.Tensor 'gradients_11/add_16_grad/tuple/control_dependency_1:0' shape=(784,) dtype=float32>, <tf.Variable 'Variable_23:0' shape=(784,) dtype=float32_ref>)]\n",
      "\n",
      "<dtype: 'float32'> (784, 10) <dtype: 'float32_ref'> (784, 10)\n",
      "\n",
      "<dtype: 'float32'> (10,) <dtype: 'float32_ref'> (10,)\n",
      "\n",
      "<dtype: 'float32'> (10, 784) <dtype: 'float32_ref'> (10, 784)\n",
      "\n",
      "<dtype: 'float32'> (784,) <dtype: 'float32_ref'> (784,)\n",
      "\n",
      "[(<tf.Tensor 'Placeholder_28:0' shape=(784, 10) dtype=float32>, <tf.Tensor 'Placeholder_29:0' shape=(784, 10) dtype=float32>), (<tf.Tensor 'Placeholder_30:0' shape=(10,) dtype=float32>, <tf.Tensor 'Placeholder_31:0' shape=(10,) dtype=float32>), (<tf.Tensor 'Placeholder_32:0' shape=(10, 784) dtype=float32>, <tf.Tensor 'Placeholder_33:0' shape=(10, 784) dtype=float32>), (<tf.Tensor 'Placeholder_34:0' shape=(784,) dtype=float32>, <tf.Tensor 'Placeholder_35:0' shape=(784,) dtype=float32>)]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_29:0' shape=(784, 10) dtype=float32>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f1bca39f6b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholder_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mupda_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholder_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m           raise TypeError(\n\u001b[1;32m    436\u001b[0m               \"Gradient must be a Tensor, IndexedSlices, or None: %s\" % g)\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m       \u001b[0mconverted_grads_and_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36m_get_processor\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SubmodelPort\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_StreamingModelPortProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trying to optimize unsupported type \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_29:0' shape=(784, 10) dtype=float32>)"
     ]
    }
   ],
   "source": [
    "# Interactive Plotting\n",
    "%matplotlib notebook \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\")\n",
    "\n",
    "# Training Constants\n",
    "learning_rate = 0.005\n",
    "batch_size = 128\n",
    "train_steps = 2000\n",
    "\n",
    "# Architecture\n",
    "d = 28**2\n",
    "h = 10\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, d])\n",
    "L = tf.placeholder(\"float\", [None, h])\n",
    "\n",
    "var_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "w_enc = tf.Variable(var_init( [d, h] ))\n",
    "b_enc = tf.Variable(var_init( [h] ))\n",
    "w_dec = tf.Variable(var_init( [h, d] ))\n",
    "b_dec = tf.Variable(var_init( [d] ))\n",
    "\n",
    "enc_X = tf.nn.relu(tf.matmul(X, w_enc) + b_enc)\n",
    "dec_X = tf.nn.relu(tf.matmul(enc_X, w_dec) + b_dec)\n",
    "\n",
    "dec = tf.nn.relu(tf.matmul(L, w_dec) + b_dec) # for use to later decoding latent codes. \n",
    "\n",
    "loss = tf.reduce_mean(tf.pow( X - dec_X, 2))\n",
    "adam = tf.train.AdamOptimizer(learning_rate)\n",
    "optimizer = adam.minimize(loss)\n",
    "\n",
    "comp_grad = adam.compute_gradients(loss, var_list=[w_enc, b_enc, w_dec, b_dec])\n",
    "\n",
    "print(comp_grad)\n",
    "placeholder_lst = []\n",
    "print(\"\")\n",
    "for i in range(4):\n",
    "    tupple = comp_grad[i]\n",
    "    g = tupple[0]\n",
    "    v = tupple[1]\n",
    "    print(g.dtype, g.shape, v.dtype, v.shape)\n",
    "    print(\"\")\n",
    "    \n",
    "    placeholder_g = tf.placeholder(g.dtype, g.shape)\n",
    "    placeholder_v = tf.placeholder(v.dtype, v.shape)\n",
    "    new_tupple = (placeholder_g, placeholder_v)\n",
    "    \n",
    "    placeholder_lst.append( new_tupple )\n",
    "    \n",
    "print(placeholder_lst)\n",
    "\n",
    "upda_grad = adam.apply_gradients(placeholder_lst)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# initialize interactive plotting\n",
    "fig, (ax_train, ax_score, ax_done) = plt.subplots(1, 3, figsize=(12,4)) \n",
    "fig.tight_layout()\n",
    "ax_train.axis(\"off\")\n",
    "ax_done.axis(\"off\")\n",
    "ax_score.set_xlim(0, train_steps)\n",
    "visualize, _ = mnist.test.next_batch(4) \n",
    "loss_vals = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(1, train_steps):\n",
    "        \n",
    "        batch, _ = mnist.train.next_batch(batch_size)\n",
    "        #_, current_loss = sess.run([optimizer, loss], feed_dict={X: batch})\n",
    "        current_loss = sess.run(loss, feed_dict={X: batch})\n",
    "        \n",
    "        \n",
    "        S = sess.run(comp_grad, feed_dict={X: batch})\n",
    "        \n",
    "        \n",
    "        sess.run(upda_grad, feed_dict={placeholder_lst: S})\n",
    "        \n",
    "        \n",
    "        \n",
    "        #sess.run(upda_grad, feed_dict={X: batch})\n",
    "        #print(len(S))\n",
    "        #print(S)\n",
    "        #print(np.shape(S))\n",
    "        \n",
    "        #sess.run(upda_grad, ?? feed_dict.. S)\n",
    "        \n",
    "        loss_vals.append(current_loss)\n",
    "        \n",
    "        #grad_ = sess.run(grad, feed_dict={X: batch})\n",
    "        #tf.gradients(dec_X, X, feed_dict={X: batch})\n",
    "        \n",
    "        \n",
    "        # Visualize cool stuff\n",
    "        if i % 100 == 0 or i == 1:  \n",
    "            \n",
    "            ax_score.plot(loss_vals, color='b')\n",
    "            fig.canvas.draw()  \n",
    "            \n",
    "            pred, current_loss = sess.run([dec_X, loss], feed_dict={X: visualize})\n",
    "            \n",
    "            sys.stdout.write(\"\\rStep: %i\\tLoss: %f\" % (i, current_loss))\n",
    "            sys.stdout.flush() \n",
    "            \n",
    "            images = np.empty((28 * 2, 28 * 2 * 2)) # add 2px space in between?\n",
    "    \n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    current_image = j + i*2\n",
    "\n",
    "                    real_image = visualize[current_image].reshape([28, 28])\n",
    "                    reconstructed_image = pred[current_image].reshape([28, 28])\n",
    "\n",
    "                    # Add original image\n",
    "                    images[i * 28: (i + 1) * 28, j * 28:(j + 1) * 28] = real_image\n",
    "\n",
    "                    # Add reconstructed image\n",
    "                    images[i * 28: (i + 1) * 28, j * 28+ 28*2:(j + 1) * 28+28*2] = reconstructed_image\n",
    "\n",
    "            ax_train.imshow(images, origin=\"upper\", cmap=\"gray\", aspect='auto')\n",
    "            fig.canvas.draw()      \n",
    "        \n",
    "    # print real images vs reconstructed images\n",
    "    batch, _ = mnist.test.next_batch(100) # !! NOTICE WE TAKE TEST DIGITS TO ENSURE NOT OVERFIT!\n",
    "    pred = sess.run(dec_X, feed_dict={X: batch})\n",
    "    \n",
    "    c = 6 \n",
    "    images = np.empty((28 * c, 28 * c * 2)) # add 2px space in between?\n",
    "    \n",
    "    for i in range(c):\n",
    "        for j in range(c):\n",
    "            current_image = j + i*c\n",
    "            \n",
    "            real_image = batch[current_image].reshape([28, 28])\n",
    "            reconstructed_image = pred[current_image].reshape([28, 28])\n",
    "            \n",
    "            # Add original image\n",
    "            images[i * 28: (i + 1) * 28, j * 28:(j + 1) * 28] = real_image\n",
    "                \n",
    "            # Add reconstructed image\n",
    "            images[i * 28: (i + 1) * 28, j * 28+ 28*c:(j + 1) * 28+28*c] = reconstructed_image\n",
    "\n",
    "      \n",
    "ax_done.imshow(images, origin=\"upper\", cmap=\"gray\", aspect='auto')\n",
    "fig.canvas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
